\subsection{Noise handling}

Especially for the CMA-ES when using the superlinear recombination, the ranking of search
points is essential to the progression of the algorithm. As the score of the Tetris controllers
is under strong influence of noise, the CMA-ES can easily rank the 
candidate solutions wrongly. As controllers are conjectured and verified to
be exponentially distributed, the further the algorithm progress, the higher the likelihood
of faulty ranking. When the ranking becomes sufficiently unreliable, the CMA-ES will
no longer be able to tell which solutions are preferable and impair further progress
of the algorithm.\\
\\
One solution to this, which we have already used, is increasing the number of evaluations
performed on each search point. In our final experiment, the CMA-ES evaluated each agent
5 times to better distinguish between good and poor performing search points. This did turn out
to benefit the algorithm slightly, but at some cost. The high number of evaluations does not have a
significant effect at early stages. We saw that learning rate is quite high in during the first 
iterations but slows down as score, and therefore noise, increases. A simple solution
that we discussed  was to increase the number of evaluations based on iteration number.
A couple of ways to set 
\begin{align}
\numberOfEvaluations &=  \max\left( 1, k \lfloor \log_{2} \left( \generation \right)  \rfloor \right) &,\ k \in \mathbb{N}^+\\
\numberOfEvaluations &=  \max\left( 1, \left \lfloor{ \frac{\generation}{k} }\right \rfloor \right) &,\ k \in \mathbb{N}^+
\end{align}
This way, the number of evaluations increase with the iteration number, and should approximately
increase with the noise. This could help overcome the faulty ranking as noise gets higher.\\
\\
A more versatile solution to ensure good ranking is an approach described by
Amine Boumaza called racing \citep{boumaza2011:b}. In racing, the goal is to 
distinguish the search search points by constructing confidence intervals around each
search point like those described in section \ref{sec:confidenceIntervals}.
This way, the search points are evaluated either until some upper limit for evaluations,
or until the confidence interval around the search point no longer overlaps it's
neighboring search points. This method for noise handling should keep the ranking 
valid as well as avoid unnecessary evaluations. The racing method is also described in 
\citep{heidrich-meisner:09c}.


