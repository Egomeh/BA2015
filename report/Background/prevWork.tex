\subsection{Previous work in learning Tetris\label{prevWork}}
Over the time, numerous researchers has tried different feature 
sets and applied various optimizers in the search of the best 
possible policy. Researches in the field
of reinforcement learning have approached the task of learning Tetris
in various ways. Some have implemented exact versions of the original game
where the artificial Tetris player will have to interact with the 
game much like a human player. In these games the state of the board is not limited
to just the board configuration and the current piece, but also where in the 
board the piece is located. Hence, these controllers does not model actions 
as locations to drop the piece, but rather 'button presses' that controls the
fall of the piece. Yet, from the literature we have read, the most commonly applied 
type of controller is the one used in the MDPTetris platform. As mentioned earlier,
to create an efficient controller one can adjust two settings, namely the feature set 
and the associated weights. 
Usually, other reseachers deals with the combined task of both
deciding the feature set and tuning the weights. A common 
feature set, the Dellacherie feature set (see figure \ref{table:dellfeat}),
was originally tuned by hand with trial and error approach with surprisingly 
good results. Yet, the most common approach is to apply an optimization 
algorithm to adjust the weighting.
The features used are typically
ones that attempt to mimic the board conditions that would
normally catch the attention of a human player, such as
how high the overall pile of pieces is and how many holes 
the board has. Table 1 \citep{scherrer2009:b}
presents some feature sets used throughout various publications
on the subject. The feature sets applied in this thesis are 
Dellacherie and the Bertsekas feature sets 
(see figure \ref{table:dellfeat} and \ref{table:bertfeat}) due 
to their recurring usage across various articles.
Many authors have had success
with applying evolutionary stochastic search methods for tuning 
the weights of the feature sets towards
efficient controllers. However, the goal of most research 
is to outperform existing controllers and push the boundaries
of performance when learning Tetris. This means that the objective of
these researchers is often to craft feature sets that perceives the 
board in a way that allows the agent to make the best possible decisions.
Thus the focus in most works is combined on finding good feature sets and 
finding good ways to optimize the weights of the set. In this thesis,
our goal is not to find a controller that outperforms any existing one,
but rather to investigate the learning properties of the optimization algorithms.
For this purpose
we are in particular addressing the
Cross-entropy method described in detail in \citep{cetut2014} and the
Covariance Matrix Adaption Evolution Strategy (CMA-ES), described 
in \citep{hansen2011}. The particular Cross-entropy method applied 
is the one described in \citep{szita:06} as the "Noisy Cross-entropy Method".\\

\begin{table}[h!]
\begin{center}
\begin{tabular}{| l | p{8cm} |}
\hline
\textbf{Feature} & \textbf{Description}\\
\hline
Landing height & The height of the last piece when it was placed\\
\hline
Eroded piece cells & Number of rows cleared in the last move
times the number of bricks cleared from the last move\\
\hline
Row transitions & Number of horizontal cell transitions\\
\hline
Column transitions & Number of vertical cell transitions \\
\hline
Holes & Number of empty cells surrounded by full cells\\
\hline
Board wells & Cumulative sum of cells to the depth of
the board wells.\\
\hline
\end{tabular}
\end{center}
\caption{features of the Dellacherie featureset \label{table:dellfeat}}
\end{table}

\begin{table}[h!]
\begin{center}
\begin{tabular}{| l | p{8cm} |}
\hline
\textbf{Feature} & \textbf{Description}\\
\hline
Max height & Height height of the highest occupied block\\
\hline
Holes & Number of empty cells surrounded by full cells\\
\hline
Column height & Height of each column\\
\hline
Height difference & The height difference between columns\\
\hline
\end{tabular}
\end{center}
\caption{features of the Dellacherie featureset \label{table:bertfeat}}
\end{table}


Currently, many researchers have proposed numerous 
feature sets and multiple 
optimization methods have been explored. 
The Dellacherie controller is very widely used across many resources
\citep{fahey}. This controller was hand-tuned by trial and error 
and did originally achieve, on a regular non-simplified Tetris game, an average of
660,000 lines. The same feature set (see figure \ref{table:dellfeat}) is 
often incorporated in later works when optimizing controllers. An earlier
feature set is the set proposed by \citep{Bertsekas} referred to as the Bertsekas and
Tsitsiklis features. In 2006, Szita and L\H{o}rincz \citep{szita:06} applied the Cross-entropy
method using the Bertsekas and Tsitsiklis features. They report that using no noise,
their controller converged at 300,000 lines on average. 
The best result reported in \citep{szita:06}
is when decreasing noise is applied, 
in which the controller's score exceeded 800,000 lines. 
However, in a later paper, using Dellacherie, 
Bertsekas and two selfdefined features achieved 
35,000,000 lines $\pm 20\%$  \citep{scherrer2009}.\\


