\section{Experiments}


This section will walk through the experiments conducted in to answer the question 
of either of the Cross-entropy method or the CMA-ES algorithm can be said to perform better
than another. The section will provide a discussion on how the experiments are carried out, mainly
in terms of how the Tetris emulator is integrated with Shark and how the games settings were configured.
Furthermore, the section covers an experiment that serves the purpose of indicating whether our implementation 
of the Cross-entropy method is similar to the ones in the literature. 
We wish ensure that both algorithms, when competing in learning Tetris, both operate under the 
best settings. To satisfy this, a series of experiments with altering settings for each 
algorithm was run to reveal how to set the parameters to get the best performance from 
each algorithm. Finally, the optimal settings for each algorithm is applied to
the same Tetris game configuration to decide if any significant difference appears.\\
\\
The experiments conducted in this section are all much in the same nature, and the 
results are for each experiment presented mostly in the same fashion. When using some setting 
of the game and the optimizers, the same experiment is executed multiple times, typically 
10 or 30 times. This is because the sore of a Tetris controller and the overall 
solution found by the optimization algorithms are influenced by some level of noise.
Due to this noise, the reported performance of an optimization algorithm at a time
is computed as the mean score of it's current solution evaluated 30 times.\\
\\
In all papers used for reference we haven't seen any experiments with different population
and parent sizes presented side-by-side. All the experiments we've seen
that has applied the Cross-entropy method to Tetris fix the population size to 100. 
However, in our upcoming experiments
CMA and the Cross-entropy method are configured with different population and parent sizes, which means
that we cannot compare the learning curves based on iterations/generations. Instead as described
in section \ref{varifyofce}, using the  
\textit{number of games played} as comparison reference, equal terms are secured for both algorithms 
in regards to learning speed.
Hence x-axis shows the total number 
of Tetris games evaluated, 
$\sum_{i = 1}^{\generation} \populationSize \numberOfEvaluations$. 
Meanwhile the y-axis still represents the mean score 
of the centroid agent at iteration $\generation$.

\input{Experiments/mdpTetris}

\input{Experiments/setup}

\input{Experiments/verifyCE}

\input{Experiments/optimalSettingsCE}

\input{Experiments/optimalSettingsCMA}


\input{Experiments/comparisons}

