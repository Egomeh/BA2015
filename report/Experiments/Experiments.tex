\section{Experiments}


This section will walk through the experiments conducted in to answer the question 
of either of the Cross Entropy method or the CMA-ES algorithms can be said to perform better
than another. The section will provide a discussion on how the experiments are carried out, mainly
in terms of how the Tetris emultaor is integrated with Shark and how the games settings were configured.
The section covers an experiment that serves the purpose of indicating whether our implementation 
of the Cross Entropy algorithm is similar to the ones in the literature. 
We wish ensure that both algorithms, when competing in learning Tetris, both operate under the 
best settings. To satisfy this, a series of experiments with altering settings for each 
algorithm was run to reveal how to set the parameters to get the best performance from 
each algorithm. Finally, the optimal settings for each algorithm is applied to
the same Tetris game configuration to decide if any significant difference appears.\\
\\
The experiments conducted in this section are all much in the same nature, and the 
results are for each experiment presented mostly in the same fashion. When using some setting 
of the game and the optimizers, the same experiment is executed multiple times, typically 
10 or 30 times. This is because the sore of a Tetris controller and the overall 
solution found by the optimization algorithms are influenced by some level of noise.
Due to this noise, the reported performance of an optimization algorithm at a time
is computed as the mean score of it's current solution evaluated 30 times.


\input{Experiments/mdpTetris}

\input{Experiments/setup}

\input{Experiments/verifyCE}

\input{Experiments/optimalSettingsCE}

\input{Experiments/optimalSettingsCMA}


\input{Experiments/comparisons}

