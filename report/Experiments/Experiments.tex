\section{Experiments}
This section will walk through the experiments conducted in order to answer the question 
of whether the Cross-entropy method or the CMA-ES algorithm can be said to perform better
than the other. The section will provide a discussion on how the experiments are carried out, mainly
in terms of how the Tetris emulator is integrated with Shark and how the game settings were configured.
Furthermore, the section covers an experiment that serves the purpose of indicating whether our implementation
of the Cross-entropy method is similar to the ones in the literature. 
We wish to ensure that both algorithms when competing in learning Tetris, both operate under the 
best performing settings. To satisfy this, a series of experiments with altering settings for each 
algorithm was conducted in the search of the parameter settings to get the best performance from 
each algorithm. Finally, the optimal settings for each algorithm is applied to
the same Tetris game configuration to decide if any significant difference appears.\\
\\
The experiments conducted in this section are all much in the same nature, and the 
results for each experiment is presented mostly in the same fashion. When using some setting 
of the game and the optimizers, the same experiment is executed multiple times, typically 
10 or 30 times. This is because the score of a Tetris controller and the overall 
solution found by the optimization algorithms are influenced by some level of noise.
Due to this noise, the reported performance of an optimization algorithm at a time
is computed as the mean score of it's current solution evaluated 30 times.
\cbcolor{blue}
The experiments will include some configuration of the Tetris emulator which are settings
such as feature set (which in turn translates into dimensionality of the problem),
piece types. Furthermore, the optimization algorithm is chosen and configured according to
the best performing settings determined in the optimization experiments. The
configuration of the optimization algorithm includes setting such as population size
$\populationSize$, parent size $\offspringNumber$ and how many times
to evaluate an agent $\numberOfEvaluations$. The number of evaluations $\numberOfEvaluations$
is how many times each search point/agent from the algorithms are evaluated against the 
Tetris emulator. For every iteration in the algorithm, the current solution is 
evaluated against Tetris emulator 30 times, and the mean of those 30 games are used as
a metric for the current state of learning at the given iteration. When results are presented 
in the following sections, we typically present plots accompanied with tables 
that hold the scores of the algorithms. We have two kinds of plots, one contains all
individual runs with a given configuration and the other shows the mean performance
of all all the runs. The tables will show the mean and quantile scores of the experiments
of a given configuration.\\
\\
In all papers used for reference we haven't seen any experiments with different population
and parent sizes presented side-by-side. All the experiments we've seen
that has applied the Cross-entropy method to Tetris fix the population size to 100. 
However, in our upcoming experiments
CMA-ES and the Cross-entropy method are configured with different population and parent sizes, which means
that we cannot compare the learning curves based on iterations/generations. Instead as described
in section \ref{varifyofce}, using the  
\textit{number of games evaluated} (the number games evaluated, number of agents evaluated and evaluations of the objective function, all refer to the same metric) as comparison reference, equal terms are secured for both algorithms 
in regards to learning speed.
Hence the x-axis represents the total number 
of Tetris games evaluated, 
$\sum_{i = 1}^{\generation} \populationSize \numberOfEvaluations$. 
Meanwhile the y-axis still represents the mean score 
of the centroid agent at iteration $\generation$.\\

\input{Experiments/mdpTetris}

\input{Experiments/setup}

\input{Experiments/verifyCE}

\input{Experiments/optimalSettingsCE}

\input{Experiments/optimalSettingsCMA}


\input{Experiments/comparisons}

