\section{Experiments}


This section will walk through the experiments conducted in to answer the question 
of either of the Cross-entropy method or the CMA-ES algorithms can be said to perform better
than another. The section will provide a discussion on how the experiments are carried out, mainly
in terms of how the Tetris emultaor is integrated with Shark and how the games settings were configured.
The section covers an experiment that serves the purpose of indicating whether our implementation 
of the Cross-entropy method is similar to the ones in the literature. 
We wish ensure that both algorithms, when competing in learning Tetris, both operate under the 
best settings. To satisfy this, a series of experiments with altering settings for each 
algorithm was run to reveal how to set the parameters to get the best performance from 
each algorithm. Finally, the optimal settings for each algorithm is applied to
the same Tetris game configuration to decide if any significant difference appears.\\
\\
The experiments conducted in this section are all much in the same nature, and the 
results are for each experiment presented mostly in the same fashion. When using some setting 
of the game and the optimizers, the same experiment is executed multiple times, typically 
10 or 30 times. This is because the sore of a Tetris controller and the overall 
solution found by the optimization algorithms are influenced by some level of noise.
Due to this noise, the reported performance of an optimization algorithm at a time
is computed as the mean score of it's current solution evaluated 30 times.
\begin{changebar}
\cbcolor{blue}
The experiments will include some configuration of the Tetris emulator which are settings
such as feature set (which in turn translates into dimensionality of the problem),
piece types.Further more, the optimization algorithm is chosen and configured. The
configuration of the optimization algorithm includes setting such as population size
$\populationSize$, parent size $\offspringNumber$ and how many times
to evaluate an agent $\numberOfEvaluations$. The number of evaluations $\numberOfEvaluations$
is how many times each search poin/agent from the algorithms are evaluated against the 
Tetris emulator. For every iteration in the algorithm, the current solution as 
evaluated against Tetris emulator 30 times, and the mean of those 30 games are used as
a metric for the current state of learning at the given iteration. When results are presented 
in the following sections, we typically present plots accompanied with tables 
that hold the scores of the algorithms. We have two kinds of plots, one contains all
individual runs with a given configuration and the other shows the mean performance
of all all the runs. The tables will show the mean and quantile scores of the experiments
of a given configuration.\end{changebar}\\
\\
In all papers used for reference we haven't seen any experiments with different population
and parent sizes presented side-by-side. All the experiments we've seen
that has applied Cross Entropy to Tetris fix the population size to 100. 
However, in our upcoming experiments
CMA and Cross Entropy are configured with different population and parent sizes, which means
that we cannot compare the learning curves based on iterations/generations. Instead as described
in section \ref{varifyofce}, using the  
\textit{number of games played} as comparison reference, equal terms are secured for both algorithms 
in regards to learning speed.
Hence x-axis shows the total number 
of Tetris games evaluated, 
$\sum_{i = 1}^{\generation} \populationSize \numberOfEvaluations$. 
Meanwhile the y-axis still represents the mean score 
of the centroid agent at iteration $\generation$.\\

\input{Experiments/mdpTetris}

\input{Experiments/setup}

\input{Experiments/verifyCE}

\input{Experiments/optimalSettingsCE}

\input{Experiments/optimalSettingsCMA}


\input{Experiments/comparisons}

