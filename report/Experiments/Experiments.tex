\section{Experiments}
This section will walk through the experiments conducted in order to investigate the performance
difference between the Cross-entropy method and the CMA-ES algorithm. The section will provide a discussion on how the experiments are carried out, mainly
in terms of how the Tetris emulator is integrated with Shark and how the game settings were configured.
Furthermore, the section covers an experiment that serves the purpose of indicating whether our implementation
of the Cross-entropy method is similar to the ones in the literature. 
We wish to ensure that both algorithms when competing in learning Tetris, both operate under the 
best performing settings. To satisfy this, we wish to obtain the parameter settings resulting in the 
best performance
for both algorithms. In order to find these settings, a series of experiments are conducted 
in order to reveal under which circumstances each of the algorithms performs best.
Finally, the optimal settings for each algorithm is applied to
the same Tetris game configuration to decide if any significant difference appears.\\
\\
The experiments conducted in this section are all much in the same nature, and the 
results for each experiment is presented mostly in the same fashion. When using some setting 
of the game and the optimizers, the same experiment is executed multiple times, typically 
10 or 30 times, hence producing 10 or 30 complete learning curves of the algorithm at a given setting.
These learning curved are often merged into one averaged learning curve used to assess the overall
performance of the algorithm at the current setting. 
The reason for executing the same experiment multiple times is a result of the noisy nature of the problem. Some experiments reaches highly variable learning curves and ends in very different results. In order to overcome this, the average of the multiple games are used as measure of the algorithms performance.
In the individual curves for each experiment, the curve along the y-axis represents the mean score of 30 games at the current solution at a given time.
The setup of an experiment includes a range of parameters. The Tetris emulator is adjusted my deciding the feature set and piece types. The feature set translates directly into dimensionality of the search space, where as piece types and frequency of these translates into the difficulty of the game.
Furthermore, the optimization algorithm is chosen and configured according to
the best performing settings determined in the optimization experiments. The
configuration of the optimization algorithm includes setting such as population size
$\populationSize$, parent size $\offspringNumber$ and how many times
to evaluate an agent $\numberOfEvaluations$. The number of evaluations $\numberOfEvaluations$
is how many times each agent from the algorithms are evaluated against the 
Tetris emulator. For every iteration in the algorithm, the current solution is 
evaluated against Tetris emulator 30 times, and the mean of those 30 games are used as
a metric for the current state of learning at the given iteration. When results are presented 
in the following sections, we typically present plots accompanied with tables 
that hold the scores of the algorithms. We have two kinds of plots, one contains all
individual runs with a given configuration and the other shows the mean performance
of all all the runs. The tables will show the mean and quantile scores of the experiments
of a given configuration.\\
\\
In all papers used for reference we haven't seen any experiments with different population
and parent sizes presented side-by-side. All the experiments we've seen
that has applied the Cross-entropy method to Tetris fix the population size to 100. 
However, in our upcoming experiments
CMA-ES and the Cross-entropy method are configured with different population and parent sizes, which means
that we cannot compare the learning curves based on iterations/generations. Instead as described
in section \ref{varifyofce}, using the  
\textit{number of games evaluated} (the number games evaluated, number of agents evaluated and evaluations of the objective function, all refer to the same metric) as comparison reference, equal terms are secured for both algorithms 
in regards to learning speed.
Hence the x-axis represents the total number 
of Tetris games evaluated, 
$\sum_{i = 1}^{\generation} \populationSize \numberOfEvaluations$. 
Meanwhile the y-axis still represents the mean score 
of the centroid agent at iteration $\generation$.\\

\input{Experiments/mdpTetris}

\input{Experiments/setup}

\input{Experiments/verifyCE}

\input{Experiments/optimalSettingsCE}

\input{Experiments/optimalSettingsCMA}


\input{Experiments/comparisons}

