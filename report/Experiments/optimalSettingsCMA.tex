\subsection{Optimal settings 
for CMA \label{optimalsettingscma}}

When finding the optimal settings for CMA we have a larger set of parameters we can adjust compared
to Cross Entropy. Again, as the same with Cross Entropy, we can adjust the population/parent size and
games per agent. Furthermore we can adjust the initial step-size, lower bound and recombination type.\\
The following sections will go into detail how these parameters affect the performance of CMA
algorithm. In the last section we will perform experiments to determine the optimal settings.

%In previous sections we focused on tuning Cross Entropy for the Tetris 
%problem. Whereas we deliberately chose not to tune CMA due to its implementation 
%into the Shark library \citep{shark08}. However, experiments with the "out of 
%the box" CMA from Shark, with default settings vs the tuned Cross Entropy
%resulted in CMA reaching convergence very fast but not achieving the same point
%limit as Cross Entropy.\\

\subsubsection{Recombination type}
Furthermore, CMA also has a unique formula for calculating the updated mean,
called the 'Recombination type' \ref{CMAtheory}. Where the recombination type
determines how much influence each of the offspring vectors has on the next
generation. Built into the CMA algorithm is three methods of recombination. 
\begin{itemize}
\item EQUAL, Each of the offspring vectors has equal influence in the generated mean. Each has $w_i = 1$.
\item LINEAR, The best of the offspring vectors has more influence. 
\item SUPERLINEAR, The vectors are weighted with a logarithmic equation. $w_i = \frac{w_i'}{\sum_{j=1}^{\mu} w_j'^+}$
\end{itemize}
As default, CMA uses Super Linear recombination. However, Tetris is a problem
with multiple local optimums in its solution space. This means, though a vector may be the best in its generation, it could be a nearby local optimum. Therefore, Super Linear recombination may not be the optimal recombination type for the Tetris problem.\\

\comment{- Weights for recombination could have a symbol? (change policy weight
symbol?)}\\
\comment{- Find Linear combination type formula of change format of itemize list}

\subsubsection{Population and selection size}
By adjusting the population size to that similar of Cross Entropy, we are able
to get a fair comparison between the two algorithms, given each generation will
contain the same number of agents. By setting the population and parent size
to the same values, we in effect test if the covariance matrix and the step-size
control has a impact on the algorithm performance compared to Cross Entropy
which does not have the features.\\
Table \ref{CMAPopulationSelectionConfigTest} displays the values that we are going
to test for the population and selection size.

\begin{table}[h]
\centering
\begin{tabular}{c c}
Population size, $\populationSize$ & Parent size, $\offspringNumber$\\
\hline
$12$ & $1$\\
$12$ & $3$\\
$12$ & $6$\\
$22$ & $2$\\
$22$ & $5$\\
$22$ & $11$\\
$50$ & $5$\\
$50$ & $12$\\
$50$ & $25$\\
$100$ & $10$\\
$100$ & $25$\\
$100$ & $50$
\end{tabular}
\caption{CMA configuration for population and parent size \label{CMAPopulationSelectionConfigTest}}
\end{table}

The experiments includes different population $N \in \{12,22,50,100\}$ and offspring sizes of either
10\%, 25\% and 50\%. We use 10\% because of the Cross Entropy recommended selection size, while
we use 25\% because of CMA's standard selection size for the EQUAL recombination type. 
Furthermore we use 50\% because of CMA's standard selection size for the LINEAR and SUPERLINEAR 
recombination type.

\subsubsection{Games per agent \label{CMAGamesPerAgentSection}}
As with Cross Entropy we can also adjust the number of games each agent plays per generation.
However, because of the recombination type for CMA, one game pr. agent may  be insufficient to assess the
performance of an agent. The Linear and Super Liner recombination types will value the better agents higher.
Therefore, it may occur that some better-on-average agent encounter an unlucky game, achieving a lower score than
it's actual potential allows. \\
Thus, evaluating each agent multiple times and using the average score for recombination may allow for a more accurate assessment.\\
Table \ref{CMAGamesPerAgent} displays the values that we are going
to test for games per agent.

\begin{table}[h]
\centering
\begin{tabular}{c}
Games per agent\\
\hline
$1$\\
$3$\\
$5$\\
$7$\\
$10$
\end{tabular}
\caption{CMA configuration for games per agent \label{CMAGamesPerAgent}}
\end{table}

The experiments includes different games per agent of $\{1,3,5,7,10\}$. We have chosen the same 
values as with Cross Entropy to get comparable results (see section \ref{GamesPerAgentCESection}).

\subsubsection{Initial step-size}
Initially, the covariance matrix of CMA in generation $\generation = 0$
is the identity matrix. The initial step-size, $\sigma_0$, will hence in 
the first iteration scale the area in which the CMA algorithm searches.
As from section \ref{normalSamples}, it's known that the scale of the 
solutions has no impact on the scores. Hence, it's assumed that the initial 
step-size should not have any major impact on the results.

\begin{figure}[H]
\centering
\begin{tabular}{r | r r r r r}
$\sigma_0$ & mean & Q1 & Q2 & Q3\\
\hline
0.1 & 50769.3 & 21301.1 & 54588.7 & 73972.4\\
0.2 & 42290.6 & 32180.2 & 42290.6 & 49337.4\\
0.5 & 53893.7 & 14211.1 & 66773.0 & 85816.7\\
0.8 & 37557.7 & 1422.8  & 15450.8 & 93719.4\\
1.0 & 49537.9 & 31369.8 & 49537.4 & 58454.6
\end{tabular}
\caption{Results of CMA-ES with adjusted initial step-size \label{CMAInitialSigmaConfigTest}}
\end{figure}

\comment{Add the data-graphs to appendix}

For the initial experiments using CMA-ES, 
the only adjusted parameter is the initial 
step-size $\sigma_0$. The configurations of step-sizes were 
$\sigma_0 \in \{0.1, 0.2, 0.5, 0.8, 1.0\}$. As the table shows,
the final mean score does not seem to change with the initial step-size.
Furthermore, the adjustment of the step-sizes does not appear to 
have a drastic impact on the mean scores. However, based on both mean score and
quantiles, the best configuration seems to be $\sigma_0 = 0.5$. This is 
is also referred to as a typical initial setting in \citep{boumaza2009}.
Therefore, the conclusion remains that the initial step-size is not critical 
for the experiment.\\

\comment{- Make sure to fully conclude that the initial step-size doesn't matter and therefore we don't
use this paramater in the upcoming experiments}

\subsubsection{Lower bound}

As with the Cross Entropy method, to avoid too early convergence, a 
certain lower threshold for the variance should be applied when 
sampling vectors for solutions. In the Cross Entropy method, a constant 
noise term $z_t = 4$ was added to the variance for each component
of the sampled vectors. When the $i$'th component in cross entropy is
sampled as follows
\begin{align*}
\individual_i &\sim \mathcal{N}\left(m, \sigma^{2}\right)\\
              &\sim \sigma \mathcal{N}\left(m, 1\right)
\end{align*}
Then $\sigma^{2} \geq 4$. To gain the same effect for the CMA, a lower bound 
is applied to the step-size. Such a bound is implemented in the Shark library
as the following, where the value of the lower bound is $l$.
\begin{align*}
\sigma  \lambda_n \geq l
\end{align*}
Where $\lambda_n$ is the lowest eigenvalue in the covariance matrix. 
When the vectors are sampled, the samples are scaled by the matrix $D$
containing the eignvalues of the covariance matrix. 
Hence, if $\sigma \lambda_n \geq l$, then the smallest scaling
that takes place is at least $l$. As the vectors are sampled
as
\reminder{Check if this is correct, 
and maybe place this in theoretical section.
Also make sure that variable names makes sense.}
\begin{align*}
\individual &\sim \mathcal{N}\left( m, \sigma^{2}C \right)
\end{align*}
To roughly resemble the constant noise configuration of Cross Entropy,
the dimension with the lowest variance must not drop below 4. 
This is achieved by setting a lower bound $l=2$. By setting this, 
the variance of the normal distribution in each dimension 
before rotation is ensured to be at least $\sigma^{2} = 4$
since $\sigma \mathcal{N}\left( 0, 1 \right) \sim 
\mathcal{N}\left( 0, \sigma^{2} \right)$.


\maybe{From this, it's assumed that the initial step-size, at least in this range,
does not have a significant impact, and the best of these runs, $\sigma_0$ is chosen
for first comparison.}
\comment{- Write stuff about our practical experiences with lower bound and add the graphs to appendix}\\
\comment{- Make sure to fully conclude that the lower bound doesn't matter and therefore we don't
use this paramater in the upcoming experiments}

\subsubsection{Experiment for finding the optimal settings}
In this in section we are going to conduct a wide variety of experiments to determine
the best settings for CMA. More specifically we are going to find the best combination for
population size, parent size and games per agent.\\
Table \ref{SuperCMAExperiment} shows the different experiments we are
going to carry out.

\begin{table}[H]
\centering
\begin{tabular}{c c l c}
Population Size & Parent size & Recombination Type & Games per Agent\\
\hline
$12$ & $1$ & EQUAL/LINEAR/SUPERLINEAR & 1/3/5/7/10\\
$12$ & $3$ & EQUAL & 1/3/5/7/10\\
$12$ & $6$ & LINEAR/SUPERLINEAR & 1/3/5/7/10\\
$22$ & $2$ & EQUAL/LINEAR/SUPERLINEAR & 1/3/5/7/10\\
$22$ & $5$ & EQUAL & 1/3/5/7/10\\
$22$ & $11$ & LINEAR/SUPERLINEAR & 1/3/5/7/10\\
$50$ & $5$ & EQUAL/LINEAR/SUPERLINEAR & 1/3/5/7/10\\
$50$ & $12$ & EQUAL & 1/3/5/7/10\\
$50$ & $25$ & LINEAR/SUPERLINEAR & 1/3/5/7/10\\
$100$ & $10$ & EQUAL/LINEAR/SUPERLINEAR & 1/3/5/7/10\\
$100$ & $25$ & EQUAL & 1/3/5/7/10\\
$100$ & $50$ & LINEAR/SUPERLINEAR & 1/3/5/7/10
\end{tabular}
\caption{Full experiments overview \label{SuperCMAExperiment}}
\end{table}

The choice behind using the above population sizes is to use the same population sizes as
when we tuned Cross Entropy (see section \ref{optimalsettingsce}). However, we use a population
size of 12 instead of 10, because a population size of 12 is the stock setting for Shark CMA \citep{shark08}.\\
In regard to the parent size, they have been determined depending on the recombination type.
We use all three different recombination types for the 10\% parent sizes to make these experiments
correspond to the Cross Entropy settings (see section \ref{optimalsettingsce}). However, Shark CMA
has predetermined parent sizes for each recombination types, 25\% for EQUAL and 50\% for both
LINEAR and SUPERLINEAR \citep{shark08}. For this reason we also conduct experiments for each population
size to represent these Shark CMA preferred settings.
Furthermore we also test different number of games per agent as for the reason presented in section
\ref{CMAGamesPerAgentSection}.\\

\textbf{Results}\\
\comment{show results, specify best resuslts/candidates.}\\

\textbf{Analysis and discussion}\\
\comment{Discuss best results/candidates and conclude the optimal settings.}\\








